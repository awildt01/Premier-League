{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2584c12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install scikit-plot\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,plot_confusion_matrix,f1_score,accuracy_score,precision_score\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from scikitplot.metrics import plot_confusion_matrix, plot_roc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing  import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from IPython.display import display\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from time import time\n",
    "from skopt import dummy_minimize\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Integer, Real\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# import Modellen\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4be39fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>team_placement_2</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>age</th>\n",
       "      <th>spieleranzahl</th>\n",
       "      <th>spieler_median</th>\n",
       "      <th>auslaender_prozent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>1.818743</td>\n",
       "      <td>76.018072</td>\n",
       "      <td>40.976190</td>\n",
       "      <td>168</td>\n",
       "      <td>33.600000</td>\n",
       "      <td>63.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>2</td>\n",
       "      <td>1.812329</td>\n",
       "      <td>76.712329</td>\n",
       "      <td>42.301370</td>\n",
       "      <td>73</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>54.810496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004</td>\n",
       "      <td>2</td>\n",
       "      <td>1.820952</td>\n",
       "      <td>76.904762</td>\n",
       "      <td>41.602410</td>\n",
       "      <td>84</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>47.945205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>1.827250</td>\n",
       "      <td>76.925000</td>\n",
       "      <td>39.031250</td>\n",
       "      <td>160</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>65.662651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>1.824366</td>\n",
       "      <td>77.070423</td>\n",
       "      <td>39.295775</td>\n",
       "      <td>71</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>56.176471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  team_placement_2    height     weight        age  spieleranzahl  \\\n",
       "0  2003                 0  1.818743  76.018072  40.976190            168   \n",
       "1  2003                 2  1.812329  76.712329  42.301370             73   \n",
       "2  2004                 2  1.820952  76.904762  41.602410             84   \n",
       "3  2005                 0  1.827250  76.925000  39.031250            160   \n",
       "4  2005                 2  1.824366  77.070423  39.295775             71   \n",
       "\n",
       "   spieler_median  auslaender_prozent  \n",
       "0       33.600000           63.095238  \n",
       "1       24.333333           54.810496  \n",
       "2       28.000000           47.945205  \n",
       "3       32.000000           65.662651  \n",
       "4       23.666667           56.176471  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datei hochladen\n",
    "median_klassifikation_team = pd.read_csv(\"median_klassifikation_team_v2.csv\")\n",
    "median_klassifikation_team.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93b8cd4",
   "metadata": {},
   "source": [
    "- **Testdaten:**  Der verbleibende Teil des Datensatzes, ebenfalls 30 %, wird für die endgültige Bewertung des Modells verwendet. Diese Daten sollten während des gesamten Trainingsprozesses nicht gesehen werden. \n",
    "\n",
    "\n",
    "- Feature **'Year'** hat eine starke Korrelation mit 'team_placement_2' deswegen würden aus den Dataset rausgenommen. \n",
    "\n",
    "\n",
    "- Feature **spieleranzahl**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fe3d4398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Daten werden aufgeteilt in 30 % Testen und 70 % Training. \n",
    "# Die Testdaten werden nur zum Schluss verwendet und werden die Realität simulieren\n",
    "train, test = train_test_split(median_klassifikation_team, test_size=0.30, random_state=42)\n",
    "\n",
    "\n",
    "# Train und Valiedirung  \n",
    "x = train.drop(columns=['team_placement_2','year','spieleranzahl'])\n",
    "y = train.drop(columns=['year','age','height','weight','auslaender_prozent','spieler_median','spieleranzahl'])\n",
    "\n",
    "# Final Model testen\n",
    "X_test = test.drop(columns=['team_placement_2','year','spieleranzahl'])\n",
    "y_test = test.drop(columns=['year','age','height','weight','auslaender_prozent','spieler_median','spieleranzahl'])\n",
    "\n",
    "\n",
    "# reset index \n",
    "x= x.reset_index(drop=True)\n",
    "y= y.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b28944fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9 entries, 27 to 26\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   year                9 non-null      int64  \n",
      " 1   team_placement_2    9 non-null      int64  \n",
      " 2   height              9 non-null      float64\n",
      " 3   weight              9 non-null      float64\n",
      " 4   age                 9 non-null      float64\n",
      " 5   spieleranzahl       9 non-null      int64  \n",
      " 6   spieler_median      9 non-null      float64\n",
      " 7   auslaender_prozent  9 non-null      float64\n",
      "dtypes: float64(5), int64(3)\n",
      "memory usage: 648.0 bytes\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aaf2e5",
   "metadata": {},
   "source": [
    "**Modelle vergleichen**\n",
    "\n",
    "Um die verschiedenen Modelle zu bewerten, wurde eine Funktion mit Kreuzvalidierung erstellt. Diese verwendet KFold zur Aufteilung der Daten und berechnet die durchschnittliche Genauigkeit sowie die Standardabweichung der Genauigkeit für jedes Modell. Um die Stabilität und Robustheit der Modelle genauer zu überprüfen, wurde die RepeatedKFold-Methode angewendet.\n",
    "\n",
    "**RepeatedKFold**:  ist ein leistungsstarkes Werkzeug, das die Zuverlässigkeit und Stabilität von Modellbewertungen verbessert, insbesondere bei **kleinen Datensätzen** oder wenn ein genauer Modellvergleich erforderlich ist. Diese Methode hilft dabei, die Varianz der Ergebnisse zu reduzieren und ermöglicht eine präzisere Einschätzung der Modellleistung.\n",
    "\n",
    "\n",
    "Sie ist besonders nützlich in den folgenden Situationen:\n",
    "\n",
    "**1. Kleine Datensätze**\n",
    "Bei kleinen Datensätzen können zufällige Aufteilungen in Trainings- und Validierungssätze stark unterschiedliche Ergebnisse liefern. RepeatedKFold hilft dabei, diese Variabilität zu reduzieren, indem sie mehrere K-Fold-Kreuzvalidierungen durchführt und die Ergebnisse mittelt.\n",
    "\n",
    "**2. Modellvergleich**\n",
    "Wenn Sie verschiedene Modelle vergleichen möchten, bietet RepeatedKFold eine robustere Bewertung, da die Modelle über mehrere Wiederholungen hinweg getestet werden. Dies reduziert die Wahrscheinlichkeit, dass die Leistung eines Modells zufällig besser oder schlechter erscheint als in der Realität.\n",
    "\n",
    "**3. Bewertung der Modellstabilität**\n",
    "Wenn Sie wissen möchten, wie stabil die Leistung Ihres Modells ist, kann RepeatedKFold durch mehrere Wiederholungen zeigen, wie sehr die Ergebnisse variieren. Ein Modell, das in allen Wiederholungen ähnlich gute Ergebnisse liefert, ist stabiler als ein Modell, dessen Leistung stark schwankt.\n",
    "\n",
    "**4. Schätzungen mit geringerer Varianz**\n",
    "Durch die Wiederholung des K-Fold-Verfahrens wird die Varianz der Leistungsschätzungen reduziert, was zu genaueren und zuverlässigeren Schätzungen führt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "56c8f6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 12.7\n",
      " \n",
      "Model: Logistic Regression\n",
      "Mean Accuracy: 0.5950\n",
      "Standard Deviation: 0.2285\n",
      "\n",
      "Model: Random Forest\n",
      "Mean Accuracy: 0.6200\n",
      "Standard Deviation: 0.2015\n",
      "\n",
      "Model: DecisionTreeClassifier\n",
      "Mean Accuracy: 0.5350\n",
      "Standard Deviation: 0.2292\n",
      "\n",
      "Model: SGDClassifier\n",
      "Mean Accuracy: 0.5450\n",
      "Standard Deviation: 0.2631\n",
      "\n",
      "Model: LGBMClassifier\n",
      "Mean Accuracy: 0.6000\n",
      "Standard Deviation: 0.2345\n",
      "\n",
      "Model: XGBClassifier\n",
      "Mean Accuracy: 0.6400\n",
      "Standard Deviation: 0.1881\n",
      "\n",
      "Model: SVC\n",
      "Mean Accuracy: 0.5900\n",
      "Standard Deviation: 0.2437\n",
      "\n",
      "Model: AdaBoostClassifier\n",
      "Mean Accuracy: 0.6500\n",
      "Standard Deviation: 0.2121\n",
      "\n",
      "Model: xgboost\n",
      "Mean Accuracy: 0.6400\n",
      "Standard Deviation: 0.1881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Kreuzvalidierungsfunktion für Klassifikation\n",
    "def cross_validate_model(models, x, y, n_splits=5):\n",
    "    \n",
    "    # Dict für die Ergbnisse\n",
    "    results = {}\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    for name, model in models:\n",
    "        accuracy_scores = []\n",
    "        \n",
    "         # KFold teilt die Daten in n_splits Folds auf.\n",
    "         # Wiederholt die K-fache Aktion n-mal mit unterschiedlicher Zufallsverteilung bei jeder Wiederholung.\n",
    "         # shuffle=True stellt sicher, dass die Daten vor der Aufteilung gemischt werden.\n",
    "         # random_state=rep Die beispiele für jeden Block werden sich ändern \n",
    "         # Arlternative lösung  kf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=2652124)\n",
    "        for rep in range(10):\n",
    "            kf = KFold(n_splits=n_splits, shuffle=True, random_state=rep)\n",
    "        \n",
    "            # Durchführen der Kreuzvalidierung\n",
    "            for train_index, val_index in kf.split(x):\n",
    "                # Aufteilen der Daten in Trainings- und Validierungs-Sets, Hier werden in den Index zugreifen.:\n",
    "                x_train, x_val = x.iloc[train_index], x.iloc[val_index]\n",
    "                y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "\n",
    "                # LabelEncoder für \"XGBClassifier\"\n",
    "                # XGBClassifier muss eine  Klassenspalte bei 0 beginnen (wie seit Version 1.3.2 erforderlich).\n",
    "                # Eine einfache Lösung hierfür ist die Verwendung von LabelEncoder aus der Bibliothek sklearn.preprocssing.\n",
    "                # Dies liegt daran, dass der y_train vor dem Training in einem \n",
    "                # neueren aktualisierten XGBoost-Modell codiert werden muss. \n",
    "                # Das heißt, Sie müssen eine kategorische Transformation wie Label-Encoder \n",
    "                le = LabelEncoder()\n",
    "                y_train = le.fit_transform(y_train)\n",
    "                \n",
    "                # Anwenden des Scalers\n",
    "                # Bei dem Training eines Machine Learning Modells ist es wichtig, dass der Skalierer lediglich an die Trainingsdaten angepasst wird und dann jedoch sowohl auf die Trainings- \n",
    "                # als auch auf die Testdaten angewandt wird. Dadurch ist die Konsistenz des Skalierungsprozesses sichergestellt.\n",
    "                #if normalaize == False:\n",
    "                x_train_s = scaler.fit_transform(x_train)\n",
    "                x_val_s = scaler.transform(x_val)\n",
    "\n",
    "                model.fit(x_train_s, y_train)\n",
    "                y_pred = model.predict(x_val_s)\n",
    "\n",
    "                # Berechnung der Genauigkeit\n",
    "                accuracy = accuracy_score(y_val, y_pred)\n",
    "                accuracy_scores.append(accuracy)\n",
    "           \n",
    "        # Accuracy und Standardabweichung in eine Liste speichern\n",
    "        mean_accuracy = np.mean(accuracy_scores)\n",
    "        std_accuracy = np.std(accuracy_scores)\n",
    "        results[name] = (mean_accuracy, std_accuracy)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Beispiel-Daten vorbereiten\n",
    "# Zielvariable ist nun der direkte Teamplatz (1 bis 20)\n",
    "\n",
    "#mean_league_team['target'] = mean_league_team['team_placement']\n",
    "\n",
    "# Features und Zielvariable trennen\n",
    "#x = mean_league_team[['age', 'height', 'weight']]\n",
    "#y = mean_league_team['target']\n",
    "\n",
    "\n",
    "\n",
    "# Liste von Modellen, die verglichen werden sollen\n",
    "models = [\n",
    "    (\"Logistic Regression\", LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')),\n",
    "    (\"Random Forest\", RandomForestClassifier(random_state=0)),\n",
    "    (\"DecisionTreeClassifier\",DecisionTreeClassifier(random_state=0)),\n",
    "    (\"SGDClassifier\",SGDClassifier(random_state=0)),\n",
    "    (\"LGBMClassifier\",LGBMClassifier(random_state=0)),\n",
    "    (\"XGBClassifier\",XGBClassifier(random_state=0)),\n",
    "    (\"SVC\",SVC(random_state=0)),\n",
    "    (\"AdaBoostClassifier\",AdaBoostClassifier(random_state=0)),\n",
    "    (\"xgboost\",XGBClassifier(random_state=0))\n",
    "]\n",
    "\n",
    "# Kreuzvalidierung durchführen und Ergebnisse speichern\n",
    "stard = time()\n",
    "results = cross_validate_model(models, x, y)\n",
    "end = time()\n",
    "time = abs(stard - end)\n",
    "print('Time:',round(time,1))\n",
    "print(\" \")\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "for name, (mean_accuracy, std_accuracy) in results.items():\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Mean Accuracy: {mean_accuracy:.4f}\")\n",
    "    print(f\"Standard Deviation: {std_accuracy:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6f724a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train und Valiedirung  year wird raus genommen wegen die Multikollinearität mit und age \n",
    "#x = median_klassifikation_team.drop(columns=['team_placement_2','year','spieleranzahl'])\n",
    "#y = median_klassifikation_team.drop(columns=['year','age','height','weight','auslaender_prozent','spieler_median','spieleranzahl'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.20, random_state=42, shuffle=True)\n",
    "\n",
    "# Anwenden des Scalers\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40acdb60",
   "metadata": {},
   "source": [
    "**Hyperparameter-Tuning**\n",
    "\n",
    "- **Bayesian Optimization:**\n",
    "\n",
    "Bayesian Optimization ist eine effiziente Methode zur Optimierung von Funktionen, die teuer zu bewerten sind. Es wird häufig im Kontext von Hyperparameter-Tuning in maschinellen Lernverfahren verwendet, wo es darauf ankommt, die besten Parameter zu finden, um die Leistung eines Modells zu maximieren oder zu minimieren.\n",
    "\n",
    "- **Wie funktioniert Bayesian Optimization?**\n",
    "\n",
    "Im Gegensatz zu klassischen Optimierungsmethoden, die systematisch oder zufällig den Parameterraum durchsuchen (z.B. Grid Search oder Random Search), nutzt Bayesian Optimization probabilistische Modelle, um die Funktion zu approximieren, die optimiert werden soll. Diese Methode integriert Wissen aus bisherigen Evaluierungen, um den nächsten Punkt zu wählen, der am vielversprechendsten ist. Dadurch wird die Anzahl der Evaluierungen minimiert und die Effizienz der Optimierung erhöht.\n",
    "\n",
    "\n",
    "**Vorteile der Bayesian Optimization**\n",
    "\n",
    "- **Effizienz:** Da Bayesian Optimization sich auf bereits vorhandenes Wissen stützt und nur vielversprechende Punkte evaluiert, ist es besonders effizient für Probleme, bei denen die Evaluierung der Funktion teuer ist.\n",
    "\n",
    "\n",
    "- **Flexibilität:** Es kann auf jede Funktion angewendet werden, die teuer zu berechnen ist und keine geschlossene Form hat.\n",
    "\n",
    "\n",
    "- **Parallelisierbarkeit:** Verschiedene Akquisitionsfunktionen können angepasst werden, um parallele Evaluierungen zu ermöglichen, was den Prozess weiter beschleunigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "57bc2af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost-Modell mit einem DecisionTreeClassifier als Basis-Estimator\n",
    "adaboost = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(random_state=42))\n",
    "\n",
    "# Definition des Hyperparameter-Suchraums\n",
    "param_space = {\n",
    "    'n_estimators': Integer(50, 200),\n",
    "    'learning_rate': Real(0.01, 0.08, prior='log-uniform'),\n",
    "    'base_estimator__max_depth': Integer(1, 10),\n",
    "    \"algorithm\": [\"SAMME.R\"]  # Algorithmus-Typ\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c9b0b624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Hyperparameter:  OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator__max_depth', 9), ('learning_rate', 0.047758216279353075), ('n_estimators', 174)])\n",
      "Beste Trainings-Score:  0.6583333333333332\n",
      "Test Accuracy: 0.8333\n"
     ]
    }
   ],
   "source": [
    "# Bayesian Optimization mit 5-facher Kreuzvalidierung\n",
    "bayes_cv_tuner = BayesSearchCV(\n",
    "     estimator=adaboost,\n",
    "    search_spaces=param_space,\n",
    "     n_iter=20,  # Anzahl der Iterationen\n",
    "    cv= RepeatedKFold(\n",
    "          n_splits=7,\n",
    "          random_state=42),  # Kreuzvalidierung mit 5 Folds auf den Trainingsdaten\n",
    "     n_jobs=-1,  # Verwende alle verfügbaren CPUs\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# # Modell mit optimierten Parametern auf den Trainingsdaten trainieren\n",
    "best_model = bayes_cv_tuner.fit(X_train, y_train)\n",
    "\n",
    "# # Die besten Hyperparameter anzeigen\n",
    "print(\"Beste Hyperparameter: \", best_model.best_params_)\n",
    "print(\"Beste Trainings-Score: \", best_model.best_score_)\n",
    "\n",
    "\n",
    "# # Testgenauigkeit auf den Testdaten\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a369f279",
   "metadata": {},
   "source": [
    "**Beste Hyperparameter:**\n",
    "\n",
    "- **algorithm: 'SAMME.R':**\n",
    "Dieser Parameter gibt an, welcher Boosting-Algorithmus verwendet wird. 'SAMME.R' ist eine verbesserte Version des ursprünglichen 'SAMME'-Algorithmus, die die Wahrscheinlichkeiten der Vorhersagen direkt verwendet und dadurch tendenziell effizienter ist.\n",
    "\n",
    "- **base_estimator__max_depth: 1:** Das ist die maximale Tiefe des Entscheidungsbaums (des Basis-Estimators). Eine Tiefe von 1 bedeutet, dass jeder Entscheidungsbaum in deinem AdaBoost-Modell ein sogenannter \"Stumpf\" ist, d.h., ein Baum mit nur einer Entscheidung pro Feature. Diese einfache Struktur reduziert das Risiko von Overfitting.\n",
    "\n",
    "- **learning_rate: 0.04**\n",
    "Die Lernrate bestimmt, wie stark neue Bäume die Fehler der vorherigen Bäume korrigieren. Eine Lernrate von 1.0 bedeutet, dass jeder Baum den Fehler der vorherigen vollständig korrigiert, was zu schnelleren Anpassungen führt.\n",
    "\n",
    "- **n_estimators: 174**\n",
    "Das ist die Anzahl der Bäume, die in der Boosting-Sequenz trainiert werden. Mehr Bäume können die Genauigkeit erhöhen, aber auch die Rechenzeit verlängern.\n",
    "\n",
    "- **Beste Trainings-Score: 0.61**\n",
    "Dieser Wert gibt an, dass das Modell mit den besten gefundenen Hyperparametern während der Cross-Validation auf den Trainingsdaten eine Genauigkeit von etwa 78,57 % erreicht hat.\n",
    "\n",
    "- **Test Accuracy: 0.83**\n",
    "Das ist die Genauigkeit des optimierten Modells auf den Testdaten, die nicht im Training verwendet wurden. Eine Testgenauigkeit von 83,33 % zeigt, dass das Modell gut generalisiert und auch auf ungesehenen Daten gute Vorhersagen macht.\n",
    "\n",
    "\n",
    "**Gesamtinterpretation:**\n",
    "- Das Modell hat eine ordentliche Leistung erbracht, wobei die Testgenauigkeit (0,8333) deutlich höher ist als der Trainings-Score (0,6583). Dies könnte darauf hinweisen, dass das Modell gut generalisiert und nicht überangepasst ist. \n",
    "\n",
    "\n",
    "- Die relativ niedrige Lernrate (0,0477) und die größere Tiefe des Basis-Schätzers (max_depth = 9) deuten darauf hin, dass das Modell detaillierte Muster in den Daten erfasst, jedoch langsam lernt, was die Generalisierungsfähigkeit unterstützt.\n",
    "\n",
    "\n",
    "- Insgesamt zeigt das Modell eine gute Balance zwischen der Modellkomplexität und der Generalisierungsfähigkeit, wie durch die relativ hohe Testgenauigkeit gezeigt wird. Es könnte jedoch von weiteren Anpassungen oder zusätzlichen Daten profitieren, um die Trainingsgenauigkeit zu erhöhen und eventuell die Testgenauigkeit weiter zu verbessern.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9c05c12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # modelo final\n",
    "# xgb = XGBClassifier(learning_rate=0.001 , n_estimators=50, max_depth=1, min_child_weight=1, gamma=0.0)\n",
    "# xgb.fit(X_train_rus, y_train_rus)\n",
    "\n",
    "# # fazer a previsão\n",
    "# X_test = scaler.transform(X_test)\n",
    "# y_pred = xgb.predict(X_test)\n",
    "\n",
    "# # Classification Report\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # imprimir a área sob a curva\n",
    "# print(\"AUC: {:.4f}\\n\".format(roc_auc_score(y_test, y_pred)))\n",
    "\n",
    "# # plotar matriz de confusão\n",
    "# plot_confusion_matrix(y_test, y_pred, normalize=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "753becc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.89         9\n",
      "   macro avg       0.58      0.67      0.62         9\n",
      "weighted avg       0.81      0.89      0.84         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ado = AdaBoostClassifier(algorithm='SAMME', learning_rate= 0.04, n_estimators=200, random_state=0)\n",
    "\n",
    "# Training \n",
    "ado.fit(X_train,y_train)\n",
    "\n",
    "# Final Test, die Daten wurden noch nicht von den Model gesehen.\n",
    "X_test = test.drop(columns=['team_placement_2','year','spieleranzahl'])\n",
    "y_test = test.drop(columns=['year','age','height','weight','auslaender_prozent','spieler_median','spieleranzahl'])\n",
    "\n",
    "\n",
    "# fazer a previsão\n",
    "X_test = scaler.transform(X_test)\n",
    "y_pred = ado.predict(X_test)\n",
    "\n",
    "# # Classification Report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "925c0e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 3]], dtype=int64)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##MATRIZ DE CONFUSÃO DO SKLEARN\n",
    "confusion_matrix(y_pred=y_pred,y_true= y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5ecbfada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test[0:9], y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ace5d8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACURÁCIA:  88.88888888888889\n",
      "F1-SCORE:  61.904761904761905\n"
     ]
    }
   ],
   "source": [
    "## ACURACIA\n",
    "print(\"ACURÁCIA: \", accuracy_score(y_pred=y_pred,y_true=y_test)*100)\n",
    "\n",
    "## F-SCORE\n",
    "print(\"F1-SCORE: \", f1_score(y_pred=y_pred,y_true=y_test,average='macro')*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71904965",
   "metadata": {},
   "source": [
    "**Metriken für jede Klasse:**\n",
    "\n",
    "**Klasse 0:**\n",
    "\n",
    "- **Precision:** 1.00: Von allen Vorhersagen, die das Modell als Klasse 0 klassifiziert hat, waren 100 % tatsächlich Klasse 0.\n",
    "- **Recall:** 1.00: Von allen tatsächlichen Instanzen der Klasse 0 hat das Modell 100 % korrekt vorhergesagt.\n",
    "- **F1-Score:** 1.00: Dies ist der harmonische Mittelwert von Precision und Recall, der ebenfalls perfekt ist.\n",
    "- **Support:** 5: Es gab 5 Instanzen der Klasse 0 in den Testdaten.\n",
    "\n",
    "**Klasse 1:**\n",
    "\n",
    "- **Precision:** 0.00: Keine der Vorhersagen für Klasse 1 war korrekt, was darauf hinweist, dass das Modell Schwierigkeiten hatte, diese Klasse zu identifizieren.\n",
    "- **Recall:** 0.00: Das Modell konnte keine der tatsächlichen Instanzen der Klasse 1 korrekt identifizieren.\n",
    "- **F1-Score:** 0.00: Dies zeigt, dass das Modell bei der Klasse 1 völlig versagt hat.\n",
    "- **Support:** 1: Es gab nur eine Instanz der Klasse 1 in den Testdaten, und das Modell hat sie nicht korrekt erkannt.\n",
    "\n",
    "**Klasse 2:**\n",
    "\n",
    "- **Precision:** 0.75: Von den Vorhersagen, die das Modell als Klasse 2 klassifiziert hat, waren 75 % korrekt.\n",
    "- **Recall:** 1.00: Von allen tatsächlichen Instanzen der Klasse 2 hat das Modell 100 % korrekt vorhergesagt.\n",
    "- **F1-Score:** 0.86: Dies zeigt eine gute, aber nicht perfekte Leistung bei der Vorhersage von Klasse 2.\n",
    "- **Support:** 3: Es gab 3 Instanzen der Klasse 2 in den Testdaten.\n",
    "\n",
    "\n",
    "**Accuracy: 0.89:** Das Modell hat insgesamt 89 % der Testinstanzen korrekt klassifiziert, was ein Hinweis darauf ist, dass das Modell im Allgemeinen gut performt.\n",
    "\n",
    "**Macro avg (Durchschnitt über alle Klassen):**\n",
    "\n",
    "- **Precision:** 0.58: Der ungewichtete Durchschnitt der Präzision über alle Klassen.\n",
    "- **Recall:** 0.67: Der ungewichtete Durchschnitt des Recalls über alle Klassen.\n",
    "- **F1-Score:** 0.62: Der ungewichtete Durchschnitt des F1-Scores über alle Klassen.\n",
    "- **Support:** 9: Die Gesamtzahl der Instanzen in den Testdaten.\n",
    "\n",
    "\n",
    "**Weighted avg (gewichteter Durchschnitt):**\n",
    "\n",
    "- **Precision:** 0.81: Der gewichtete Durchschnitt der Präzision unter Berücksichtigung des Supports jeder Klasse.\n",
    "- **Recall:** 0.89: Der gewichtete Durchschnitt des Recalls.\n",
    "- **F1-Score:** 0.84: Der gewichtete Durchschnitt des F1-Scores.\n",
    "\n",
    "**Gesamtinterpretation:**\n",
    "\n",
    "Das Modell zeigt insgesamt eine gute Leistung, besonders bei den Klassen 0 und 2. Allerdings hat es Schwierigkeiten mit Klasse 1, die möglicherweise aufgrund der geringen Anzahl an Instanzen in den Daten und/oder der Schwierigkeit, diese Klasse von den anderen zu unterscheiden, entstanden sind. Dies führt zu einem niedrigen Macro Average, aber der Weighted Average bleibt hoch, da die meisten Instanzen richtig klassifiziert wurden. Es könnte sinnvoll sein, Methoden wie das Oversampling oder das Anpassen der Klassenverteilung zu verwenden, um die Leistung für Klasse 1 zu verbessern.\n",
    "\n",
    "Die weighted average Werte sind höher als die macro average Werte, was darauf hinweist, dass das Modell bei den häufigeren Klassen (0 und 2) besser abgeschnitten hat.\n",
    "Um das Modell zu verbessern, könnte man versuchen, mehr Daten für Klasse 1 zu sammeln oder Methoden wie das Anpassen der Klassenverhältnisse oder die Anwendung von Gewichtungen in den Verlustfunktionen in Betracht ziehen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092ab21c",
   "metadata": {},
   "source": [
    "**FEATURE IMPORTANCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8c7fcc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('height', 0.07153785591168502)\n",
      "('weight', 0.0953934910687356)\n",
      "('age', 0.12690709539936024)\n",
      "('spieler_median', 0.05223658213714126)\n",
      "('auslaender_prozent', 0.6539249754830776)\n"
     ]
    }
   ],
   "source": [
    "for i in zip(x.columns, ado.feature_importances_):\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371dccc2",
   "metadata": {},
   "source": [
    "('height', 0.0)\n",
    "('weight', 0.06589573508917418)\n",
    "('age', 0.079342765233142)\n",
    "('spieler_median', 0.0)\n",
    "('auslaender_prozent', 0.8547614996776842)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f2c2c866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 5\n",
    "feat_importances = pd.Series(ado.feature_importances_, index=x.columns)\n",
    "feat_importances.nlargest(4).plot(kind='barh',colormap='Paired')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f8f102",
   "metadata": {},
   "source": [
    "1. Höhe (height):\n",
    "\n",
    "     - Die Höhe der Spieler hat eine Feature-Importance von etwa 0,0715. Dies bedeutet, dass die Höhe einen gewissen, aber nicht dominanten Einfluss auf die Klassifikation im Modell hat. Es könnte sein, dass die Körpergröße in gewissen Kontexten eine Rolle spielt, zum Beispiel bei spezifischen Positionen oder Spielstilen, aber sie ist nicht das entscheidende Merkmal.\n",
    "\n",
    "\n",
    "2. Gewicht (weight):\n",
    "\n",
    "   -  Das Gewicht der Spieler zeigt eine etwas höhere Bedeutung mit einem Wert von 0,0954. Dies könnte darauf hinweisen, dass das Gewicht ein etwas relevanterer Faktor für die Klassifikation ist, vielleicht im Zusammenhang mit der körperlichen Präsenz auf dem Spielfeld oder der Position der Spieler.\n",
    "   \n",
    "\n",
    "3. Alter (age):\n",
    "\n",
    "    - Das Alter hat eine Feature-Importance von 0,1269, was es zu einem wichtigen Merkmal macht. Dies deutet darauf hin, dass das Alter der Spieler eine signifikante Rolle spielt, möglicherweise weil es mit Erfahrung, Fitness oder Leistungsfähigkeit korreliert ist.\n",
    "    \n",
    "\n",
    "4. Median der Spieleranzahl (spieler_median):\n",
    "\n",
    "    - Mit einer Feature-Importance von 0,0522 hat dieses Merkmal den geringsten Einfluss auf das Modell. Dies könnte bedeuten, dass die Anzahl der Spieler im Kader in Bezug auf die Zielvariable weniger relevant ist, zumindest im Kontext dieses spezifischen Datensatzes und Modells.\n",
    "    \n",
    "\n",
    "5. Prozentsatz der ausländischen Spieler (auslaender_prozent):\n",
    "\n",
    "    - Der Prozentsatz der ausländischen Spieler sticht mit einer Feature-Importance von 0,6539 deutlich hervor. Dieses Merkmal ist mit Abstand das wichtigste für das Modell und könnte stark mit dem Erfolg oder der Platzierung der Mannschaften korreliert sein. Ein hoher Anteil ausländischer Spieler könnte auf eine bessere internationale Qualität hinweisen oder andere Vorteile mit sich bringen, die sich positiv auf die Leistung der Mannschaft auswirken.\n",
    "\n",
    "**Zusammenfassung**\n",
    "\n",
    "Das AdaBoost-Modell zeigt, dass der Prozentsatz der ausländischen Spieler der wichtigste Faktor ist, der die Zielvariable beeinflusst, gefolgt vom Alter der Spieler und Gewicht. Höhe und Median der Spieleranzahl spielen eine untergeordnete Rolle. Diese Analyse kann Hinweise darauf geben, welche Faktoren in zukünftigen Modellen oder Entscheidungen stärker berücksichtigt werden sollten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ddd362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
